====== Optimizing ======

In this section you will learn how to use several optimisation options.
You can can increase dramatically the simulator speed so pay attention !

===== Simulator's options =====

==== profiling ====

When running your simulation with the GLISS librairie through the generated main,
you can activate option :
<code>
-p or -profile=<path_name>
</code>
This option produce a profiling file which contains statistics about the instruction numbers of calls.
Here is the head of the produced file:
<code>
profiling statistics generated by GLISS2 for :
PROC_NAME
| instruction name | instruction identifier (cf. module id.h) | call count |
</code>

The rest of the file is a list sorted by descending number of instruction calls.
For instance, for PowerPC :
<code>
PPC_LWZ_RD_D_LP_RD_RP_ 1 1066162
PPC_OR_RD_RD_RD 2 533975
PPC_STW_RD_D_LP_RD_RP_ 3 414441
PPC_RLWINM_RD_RD_D_D_D 4 364428
// And so on for the rest of the NML instruction set...
</code>

If ''-p'' option is used, the simulator seeks for an existing profiling file,
load it and merge new statistics with the older ones. If the file does not exists, it is created.
You can also specify the profiling file path with ''-profile=path''.
This way, it is easy to produce a profiling file for an entire set of benchmarks.

This kind of option is not an optimisation by itself, of course,
but the profiling file will be usefull for what other optimizations (see -p and -PJ options down this section).
He can also help to see which instructions deserved more optimisation inside the NML.
We must keep in mind that bad NML implementation leads to bad performance.


==== Statistics ====

Default simulator main provide two options to collect statistics in order to guide you in your quest of speed:

<code>
-s or -stat
-more-stats
</code>

''-s'' display the time of the simulation and the speed in Mips.
Measures are perfomed with the function ''rusage'' (see linux [[http://www.opengroup.org/onlinepubs/009695399/functions/getrusage.html|man pages]]).
Speed and time are computed with the process user time.

''-more-stats'' displays the process system time thanks to rusage.
It also display speed and time with the function ''getgettimeofday'' (see linux [[http://www.opengroup.org/onlinepubs/000095399/functions/gettimeofday.html|man pages]]).

==== full speed simulation ====

Through ''api.h'', GLISS provides severals methods to simulate a program.
<code>
void gliss_run_sim(gliss_sim_t *sim);
void gliss_step(gliss_sim_t *sim);
</code>

It is good to know that ''gliss_run_sim'' is way faster than ''gliss_step''
(more oriented for cycle-level simulation). When running the simulation through the default main,
you can simulate with ''gliss_run_sim'' by activating options :
<code>
-f or -fast
</code>

===== GEP's options =====

When generating a new simulator with GEP,
you can improve performances by using the right modules and options

==== Faster modules ====

Here is a list of different decoding modules sort by order of speed:

   * ''decode'' -- standard module (slowest speed)
   * ''decode32_inf_cache'' -- every decoded instruction is cached (use this module at your own risk as itcould severly bloat your memory!)
   * ''decode32_fixed_cache'' -- every instructions are cached erasing the oldest inserted instruction (FIFO replacement)
   * ''decode32_lru_cache'' -- every instruction is cached erasing the oldest used instruction (LRU replacement)
   * ''decode32_trace'' -- provide a method to decode an entire block of instructions and thus accelerate the simulation by reducing the calls to decode
   * ''decode32_dtrace'' -- identical to the previous module but size of decoded block is dynamic

N.B. ''decode32_*'' modules are specialized to deal with 32 bit instructions only.

Blocks are decoded up to the next instruction branch as it guaranties a consistent execution when executing an entire block without any further check.
**WARNING** this module must be used with the option ''-gen-with-trace'' which indicates to GEP that NML has been consistently written with attribute ''set_attr_branch = 1''.
''set_attr_branch = 1'' must be declared on instructions modifying the control flow, as branches, in order to correctly find the end of a block.
If you forget to tag a single instruction branch with this attribute, and at the same time you use this module, GEP will not see the error and your simulation will be inconsistent!

To select a decoder module, call GEP with options:
<code>
-m decode:MODULE_NAME
</code>

Three optimized memory modules are availables :
   * ''fast_mem'' -- standard memory module with a two-levels depth hashtable.
   * ''vfast_mem'' --  faster module with a one level hashtable, and a better endianness handling (it does not byte swap memory at each memory acces when endianness differs from NML to host machine)
   * ''mem16'' -- fast module for 16 bit addressed memory, data are stored directly in a 2^16 bytes array.

Call GEP with:
<code>
-m mem:MODULE_NAME
</code>
in order to select the desired decode module



==== Generation options ====


=== Minor option ===

Here two options which could possibly accelerate the simulation:

  * ''-on GLISS_INSTR_FAST_STRUCT'' -- modifies the way an instruction is represented in GLISS (in a more compact and fast way)
  * ''-on GLISS_NO_MALLOC'' -- pre-allocated instructions objects at init time
instead of doing so dynamically at decode time
  * ''-on NO_PAGE_INIT'' -- disable initialization of memory page with 0 (improve speed)


=== Profiling ===

In order to generate a profiled simulator for a set of benches you can use two options :

<code>
-p PROFILE_PATH
-PJ NB_INSTRCUTION // Can be activated if '-p <profile_path>' is activated
</code>

The first option tells GEP where is the profile file in order to generate profiled C code for the simulator.
It basically sort function by order of frequenct considering the profile file.
It is a mandatory option for the nest one : ''-PJ nb_instructions''.

PJ stands for profiled jump.
One big bottleneck of a simulator are the jumps made to the differents instructions handlers (which simulate the instructions).
Most of the time handler function are stored into a table and executed through the table.
<code>
handler_table[instruction_identifier](operand0, operand1 ...)
</code>
It is a costly operation.

''-PJ n'' option inline //n// instruction handler code into a switch
<code>
switch(instruction_identifier)
case 0: // inline handler's code
case 1: // ...
// n times
default: handler_table[instruction_identifier](operand0, operand1 ...)
</code>

Of course the //n// inlined instructions are sorted by the profiling file.
Most of the time 15 is a good value to improve performances.
But we recommand to find it by yourself as it is indeed architecture dependent.

Another trick to win some extra MIPS is to compile with gcc option ''-fno-jump-table''.
But the optimal value for //n// will be usually greater. Here again only experiment can guide you.




=== Parse branch attribute ===

By default GLISS ignore the attribute 'set_attr_branch = 1', you will have to specify by activating the GEP option :
<code>
-gen-with-trace
</code>

By doing so you tell GLISS to use branch attribute for optimisation,
a different decode table will be generated and the use of decoding module ''decode32_dtrace'' will be mandatory (see description of this module).

Last warning about this option: you must not forget the tag ''set_attr_branch = 1'' on branch instruction because GEP will not see it.
If you do so, your simulator will simulate inconsistent program and most likly craches with an ''unknow instruction at addr xxxxxxx''.
Hopefully such an error will not pass cosimulation with validator either.







